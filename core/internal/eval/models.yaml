# Model Registry Data
# Static capability data for all known LLM models.
# Scores are based on public benchmarks and documented capabilities.
# Principle: LOOKUP, DON'T COMPUTE - No API calls or benchmarking needed.

# Tier definitions:
#   frontier: 90-100 score (claude-opus-4, o1-preview)
#   xl:       76-89 score (llama3:70b, gpt-4o)
#   large:    56-75 score (qwen2.5-coder:14b, claude-3-haiku)
#   medium:   36-55 score (llama3:8b, mistral:7b)
#   small:    0-35 score (llama3.2:1b, phi-mini)

models:
  # ═══════════════════════════════════════════════════════════════════════════════
  # ANTHROPIC MODELS
  # ═══════════════════════════════════════════════════════════════════════════════
  anthropic:
    - id: anthropic/claude-opus-4-20250514
      model: claude-opus-4-20250514
      display_name: Claude Opus 4
      tier: frontier
      score:
        overall: 98
        reasoning: 99
        coding: 97
        instruction: 98
        speed: 65
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 15.00
        output_per_1m: 75.00
      context_window: 200000
      aliases:
        - claude-opus-4
        - opus-4

    - id: anthropic/claude-sonnet-4-20250514
      model: claude-sonnet-4-20250514
      display_name: Claude Sonnet 4
      tier: frontier
      score:
        overall: 92
        reasoning: 93
        coding: 94
        instruction: 92
        speed: 82
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 3.00
        output_per_1m: 15.00
      context_window: 200000
      aliases:
        - claude-sonnet-4
        - sonnet-4

    - id: anthropic/claude-3-5-sonnet-20241022
      model: claude-3-5-sonnet-20241022
      display_name: Claude 3.5 Sonnet
      tier: xl
      score:
        overall: 88
        reasoning: 89
        coding: 90
        instruction: 88
        speed: 80
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 3.00
        output_per_1m: 15.00
      context_window: 200000
      aliases:
        - claude-3.5-sonnet
        - claude-3-5-sonnet

    - id: anthropic/claude-3-5-haiku-20241022
      model: claude-3-5-haiku-20241022
      display_name: Claude 3.5 Haiku
      tier: large
      score:
        overall: 65
        reasoning: 63
        coding: 68
        instruction: 66
        speed: 95
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 0.80
        output_per_1m: 4.00
      context_window: 200000
      aliases:
        - claude-3.5-haiku
        - claude-3-5-haiku
        - haiku

    - id: anthropic/claude-3-opus-20240229
      model: claude-3-opus-20240229
      display_name: Claude 3 Opus
      tier: frontier
      score:
        overall: 90
        reasoning: 92
        coding: 88
        instruction: 90
        speed: 60
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 15.00
        output_per_1m: 75.00
      context_window: 200000
      aliases:
        - claude-3-opus

    - id: anthropic/claude-3-haiku-20240307
      model: claude-3-haiku-20240307
      display_name: Claude 3 Haiku
      tier: medium
      score:
        overall: 52
        reasoning: 50
        coding: 55
        instruction: 53
        speed: 98
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 0.25
        output_per_1m: 1.25
      context_window: 200000
      aliases:
        - claude-3-haiku

  # ═══════════════════════════════════════════════════════════════════════════════
  # OPENAI MODELS
  # ═══════════════════════════════════════════════════════════════════════════════
  openai:
    - id: openai/o1
      model: o1
      display_name: O1
      tier: frontier
      score:
        overall: 95
        reasoning: 99
        coding: 92
        instruction: 90
        speed: 40
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 15.00
        output_per_1m: 60.00
      context_window: 200000
      aliases:
        - o1-2024-12-17

    - id: openai/o1-mini
      model: o1-mini
      display_name: O1 Mini
      tier: xl
      score:
        overall: 78
        reasoning: 85
        coding: 80
        instruction: 75
        speed: 60
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: false
        streaming: false
        system_prompt: false
      pricing:
        input_per_1m: 3.00
        output_per_1m: 12.00
      context_window: 128000
      aliases: []

    - id: openai/gpt-4o
      model: gpt-4o
      display_name: GPT-4o
      tier: frontier
      score:
        overall: 90
        reasoning: 91
        coding: 89
        instruction: 90
        speed: 80
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 2.50
        output_per_1m: 10.00
      context_window: 128000
      aliases:
        - gpt-4o-2024-11-20

    - id: openai/gpt-4o-mini
      model: gpt-4o-mini
      display_name: GPT-4o Mini
      tier: medium
      score:
        overall: 55
        reasoning: 52
        coding: 58
        instruction: 56
        speed: 92
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 0.15
        output_per_1m: 0.60
      context_window: 128000
      aliases: []

    - id: openai/gpt-4-turbo
      model: gpt-4-turbo
      display_name: GPT-4 Turbo
      tier: xl
      score:
        overall: 85
        reasoning: 87
        coding: 84
        instruction: 85
        speed: 70
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 10.00
        output_per_1m: 30.00
      context_window: 128000
      aliases:
        - gpt-4-turbo-preview

    - id: openai/gpt-4
      model: gpt-4
      display_name: GPT-4
      tier: xl
      score:
        overall: 82
        reasoning: 85
        coding: 80
        instruction: 82
        speed: 60
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 30.00
        output_per_1m: 60.00
      context_window: 8192
      aliases: []

    - id: openai/gpt-3.5-turbo
      model: gpt-3.5-turbo
      display_name: GPT-3.5 Turbo
      tier: medium
      score:
        overall: 45
        reasoning: 42
        coding: 48
        instruction: 46
        speed: 95
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 0.50
        output_per_1m: 1.50
      context_window: 16385
      aliases:
        - gpt-3.5-turbo-16k

  # ═══════════════════════════════════════════════════════════════════════════════
  # GOOGLE GEMINI MODELS
  # ═══════════════════════════════════════════════════════════════════════════════
  gemini:
    - id: gemini/gemini-1.5-pro
      model: gemini-1.5-pro
      display_name: Gemini 1.5 Pro
      tier: xl
      score:
        overall: 85
        reasoning: 86
        coding: 83
        instruction: 85
        speed: 75
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 1.25
        output_per_1m: 5.00
      context_window: 2000000
      aliases:
        - gemini-1.5-pro-latest

    - id: gemini/gemini-1.5-flash
      model: gemini-1.5-flash
      display_name: Gemini 1.5 Flash
      tier: large
      score:
        overall: 65
        reasoning: 62
        coding: 68
        instruction: 66
        speed: 95
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 0.075
        output_per_1m: 0.30
      context_window: 1000000
      aliases:
        - gemini-1.5-flash-latest

    - id: gemini/gemini-1.5-flash-8b
      model: gemini-1.5-flash-8b
      display_name: Gemini 1.5 Flash 8B
      tier: medium
      score:
        overall: 50
        reasoning: 48
        coding: 52
        instruction: 51
        speed: 98
        confidence: 0.95
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 0.0375
        output_per_1m: 0.15
      context_window: 1000000
      aliases: []

    - id: gemini/gemini-2.0-flash-exp
      model: gemini-2.0-flash-exp
      display_name: Gemini 2.0 Flash (Exp)
      tier: large
      score:
        overall: 72
        reasoning: 70
        coding: 75
        instruction: 72
        speed: 90
        confidence: 0.90
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 0.10
        output_per_1m: 0.40
      context_window: 1000000
      aliases:
        - gemini-2.0-flash

    - id: gemini/gemini-pro
      model: gemini-pro
      display_name: Gemini Pro
      tier: large
      score:
        overall: 60
        reasoning: 58
        coding: 62
        instruction: 61
        speed: 85
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 0.50
        output_per_1m: 1.50
      context_window: 32768
      aliases:
        - gemini-1.0-pro

  # ═══════════════════════════════════════════════════════════════════════════════
  # XAI GROK MODELS
  # ═══════════════════════════════════════════════════════════════════════════════
  grok:
    - id: grok/grok-3
      model: grok-3
      display_name: Grok-3
      tier: xl
      score:
        overall: 88
        reasoning: 90
        coding: 85
        instruction: 88
        speed: 70
        confidence: 0.85
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 3.00
        output_per_1m: 15.00
      context_window: 131072
      aliases: []

    - id: grok/grok-3-fast
      model: grok-3-fast
      display_name: Grok-3 Fast
      tier: xl
      score:
        overall: 82
        reasoning: 84
        coding: 80
        instruction: 82
        speed: 88
        confidence: 0.85
      capabilities:
        vision: true
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 1.00
        output_per_1m: 5.00
      context_window: 131072
      aliases: []

    - id: grok/grok-2
      model: grok-2
      display_name: Grok-2
      tier: large
      score:
        overall: 75
        reasoning: 76
        coding: 74
        instruction: 75
        speed: 80
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: true
        json_mode: true
        streaming: true
        system_prompt: true
      pricing:
        input_per_1m: 2.00
        output_per_1m: 10.00
      context_window: 131072
      aliases: []

  # ═══════════════════════════════════════════════════════════════════════════════
  # OLLAMA / LOCAL MODELS
  # ═══════════════════════════════════════════════════════════════════════════════
  ollama:
    # ───────────────────────────────────────────────────────────────────────────
    # LLAMA FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/llama3.2:1b
      model: llama3.2:1b
      display_name: Llama 3.2 1B
      tier: small
      score:
        overall: 30
        reasoning: 25
        coding: 28
        instruction: 35
        speed: 99
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases: []

    - id: ollama/llama3.2:3b
      model: llama3.2:3b
      display_name: Llama 3.2 3B
      tier: medium
      score:
        overall: 38
        reasoning: 35
        coding: 36
        instruction: 42
        speed: 95
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases:
        - llama3.2:latest

    - id: ollama/llama3:8b
      model: llama3:8b
      display_name: Llama 3 8B
      tier: medium
      score:
        overall: 55
        reasoning: 52
        coding: 54
        instruction: 58
        speed: 85
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases:
        - llama3:latest

    - id: ollama/llama3.1:8b
      model: llama3.1:8b
      display_name: Llama 3.1 8B
      tier: large
      score:
        overall: 58
        reasoning: 55
        coding: 57
        instruction: 60
        speed: 85
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 128000
      aliases:
        - llama3.1:latest

    - id: ollama/llama3:70b
      model: llama3:70b
      display_name: Llama 3 70B
      tier: xl
      score:
        overall: 82
        reasoning: 80
        coding: 78
        instruction: 85
        speed: 35
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases: []

    - id: ollama/llama3.1:70b
      model: llama3.1:70b
      display_name: Llama 3.1 70B
      tier: xl
      score:
        overall: 85
        reasoning: 83
        coding: 82
        instruction: 88
        speed: 30
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 128000
      aliases: []

    # ───────────────────────────────────────────────────────────────────────────
    # MISTRAL FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/mistral:7b
      model: mistral:7b
      display_name: Mistral 7B
      tier: medium
      score:
        overall: 52
        reasoning: 50
        coding: 52
        instruction: 55
        speed: 88
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 32768
      aliases:
        - mistral:latest

    - id: ollama/mixtral:8x7b
      model: mixtral:8x7b
      display_name: Mixtral 8x7B
      tier: large
      score:
        overall: 70
        reasoning: 68
        coding: 70
        instruction: 72
        speed: 55
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 32768
      aliases:
        - mixtral:latest

    - id: ollama/mixtral:8x22b
      model: mixtral:8x22b
      display_name: Mixtral 8x22B
      tier: xl
      score:
        overall: 78
        reasoning: 76
        coding: 78
        instruction: 80
        speed: 30
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 65536
      aliases: []

    # ───────────────────────────────────────────────────────────────────────────
    # QWEN FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/qwen2.5:7b
      model: qwen2.5:7b
      display_name: Qwen2.5 7B
      tier: medium
      score:
        overall: 55
        reasoning: 54
        coding: 56
        instruction: 55
        speed: 85
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 32768
      aliases:
        - qwen2.5:latest

    - id: ollama/qwen2.5:14b
      model: qwen2.5:14b
      display_name: Qwen2.5 14B
      tier: large
      score:
        overall: 68
        reasoning: 66
        coding: 70
        instruction: 68
        speed: 65
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 32768
      aliases: []

    - id: ollama/qwen2.5:32b
      model: qwen2.5:32b
      display_name: Qwen2.5 32B
      tier: large
      score:
        overall: 75
        reasoning: 73
        coding: 77
        instruction: 75
        speed: 50
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 32768
      aliases: []

    - id: ollama/qwen2.5:72b
      model: qwen2.5:72b
      display_name: Qwen2.5 72B
      tier: xl
      score:
        overall: 85
        reasoning: 84
        coding: 86
        instruction: 85
        speed: 25
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 32768
      aliases: []

    - id: ollama/qwen2.5-coder:7b
      model: qwen2.5-coder:7b
      display_name: Qwen2.5 Coder 7B
      tier: large
      score:
        overall: 58
        reasoning: 52
        coding: 68
        instruction: 55
        speed: 85
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 32768
      aliases:
        - qwen2.5-coder:latest

    - id: ollama/qwen2.5-coder:14b
      model: qwen2.5-coder:14b
      display_name: Qwen2.5 Coder 14B
      tier: large
      score:
        overall: 70
        reasoning: 65
        coding: 80
        instruction: 68
        speed: 65
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 32768
      aliases: []

    - id: ollama/qwen2.5-coder:32b
      model: qwen2.5-coder:32b
      display_name: Qwen2.5 Coder 32B
      tier: xl
      score:
        overall: 78
        reasoning: 72
        coding: 88
        instruction: 75
        speed: 45
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 32768
      aliases: []

    # ───────────────────────────────────────────────────────────────────────────
    # CODE LLAMA FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/codellama:7b
      model: codellama:7b
      display_name: Code Llama 7B
      tier: large
      score:
        overall: 58
        reasoning: 52
        coding: 70
        instruction: 55
        speed: 88
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 16384
      aliases:
        - codellama:latest

    - id: ollama/codellama:13b
      model: codellama:13b
      display_name: Code Llama 13B
      tier: large
      score:
        overall: 65
        reasoning: 60
        coding: 75
        instruction: 62
        speed: 70
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 16384
      aliases: []

    - id: ollama/codellama:34b
      model: codellama:34b
      display_name: Code Llama 34B
      tier: large
      score:
        overall: 75
        reasoning: 70
        coding: 85
        instruction: 72
        speed: 45
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 16384
      aliases: []

    - id: ollama/codellama:70b
      model: codellama:70b
      display_name: Code Llama 70B
      tier: xl
      score:
        overall: 82
        reasoning: 78
        coding: 90
        instruction: 80
        speed: 30
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 16384
      aliases: []

    # ───────────────────────────────────────────────────────────────────────────
    # DEEPSEEK FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/deepseek-coder:6.7b
      model: deepseek-coder:6.7b
      display_name: DeepSeek Coder 6.7B
      tier: medium
      score:
        overall: 55
        reasoning: 48
        coding: 68
        instruction: 52
        speed: 85
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 16384
      aliases:
        - deepseek-coder:latest

    - id: ollama/deepseek-coder:33b
      model: deepseek-coder:33b
      display_name: DeepSeek Coder 33B
      tier: large
      score:
        overall: 75
        reasoning: 68
        coding: 85
        instruction: 72
        speed: 40
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 16384
      aliases: []

    - id: ollama/deepseek-r1:8b
      model: deepseek-r1:8b
      display_name: DeepSeek R1 8B
      tier: large
      score:
        overall: 58
        reasoning: 65
        coding: 55
        instruction: 55
        speed: 80
        confidence: 0.85
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 32768
      aliases:
        - deepseek-r1:latest

    - id: ollama/deepseek-r1:70b
      model: deepseek-r1:70b
      display_name: DeepSeek R1 70B
      tier: xl
      score:
        overall: 88
        reasoning: 95
        coding: 82
        instruction: 85
        speed: 25
        confidence: 0.85
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 32768
      aliases: []

    # ───────────────────────────────────────────────────────────────────────────
    # GEMMA FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/gemma:2b
      model: gemma:2b
      display_name: Gemma 2B
      tier: small
      score:
        overall: 32
        reasoning: 30
        coding: 32
        instruction: 35
        speed: 98
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases: []

    - id: ollama/gemma:7b
      model: gemma:7b
      display_name: Gemma 7B
      tier: medium
      score:
        overall: 48
        reasoning: 46
        coding: 48
        instruction: 50
        speed: 85
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases:
        - gemma:latest

    - id: ollama/gemma2:9b
      model: gemma2:9b
      display_name: Gemma 2 9B
      tier: large
      score:
        overall: 58
        reasoning: 56
        coding: 58
        instruction: 60
        speed: 82
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases:
        - gemma2:latest

    - id: ollama/gemma2:27b
      model: gemma2:27b
      display_name: Gemma 2 27B
      tier: large
      score:
        overall: 72
        reasoning: 70
        coding: 72
        instruction: 74
        speed: 55
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases: []

    # ───────────────────────────────────────────────────────────────────────────
    # PHI FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/phi:2.7b
      model: phi:2.7b
      display_name: Phi 2.7B
      tier: medium
      score:
        overall: 42
        reasoning: 44
        coding: 40
        instruction: 42
        speed: 95
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 2048
      aliases:
        - phi:latest

    - id: ollama/phi-2
      model: phi-2
      display_name: Phi-2
      tier: medium
      score:
        overall: 48
        reasoning: 50
        coding: 46
        instruction: 48
        speed: 92
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 2048
      aliases: []

    - id: ollama/phi3:mini
      model: phi3:mini
      display_name: Phi-3 Mini
      tier: medium
      score:
        overall: 52
        reasoning: 54
        coding: 50
        instruction: 52
        speed: 95
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 4096
      aliases:
        - phi3:latest

    - id: ollama/phi3:medium
      model: phi3:medium
      display_name: Phi-3 Medium
      tier: large
      score:
        overall: 62
        reasoning: 65
        coding: 60
        instruction: 62
        speed: 75
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases: []

    # ───────────────────────────────────────────────────────────────────────────
    # YI FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/yi:6b
      model: yi:6b
      display_name: Yi 6B
      tier: medium
      score:
        overall: 50
        reasoning: 48
        coding: 50
        instruction: 52
        speed: 85
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 4096
      aliases:
        - yi:latest

    - id: ollama/yi:34b
      model: yi:34b
      display_name: Yi 34B
      tier: large
      score:
        overall: 72
        reasoning: 70
        coding: 72
        instruction: 74
        speed: 45
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 4096
      aliases: []

    # ───────────────────────────────────────────────────────────────────────────
    # SOLAR FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/solar:10.7b
      model: solar:10.7b
      display_name: Solar 10.7B
      tier: large
      score:
        overall: 62
        reasoning: 60
        coding: 62
        instruction: 64
        speed: 75
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 4096
      aliases:
        - solar:latest

    # ───────────────────────────────────────────────────────────────────────────
    # VICUNA FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/vicuna:7b
      model: vicuna:7b
      display_name: Vicuna 7B
      tier: medium
      score:
        overall: 48
        reasoning: 46
        coding: 48
        instruction: 50
        speed: 88
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 2048
      aliases:
        - vicuna:latest

    - id: ollama/vicuna:13b
      model: vicuna:13b
      display_name: Vicuna 13B
      tier: large
      score:
        overall: 58
        reasoning: 56
        coding: 58
        instruction: 60
        speed: 70
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 2048
      aliases: []

    - id: ollama/vicuna:33b
      model: vicuna:33b
      display_name: Vicuna 33B
      tier: large
      score:
        overall: 68
        reasoning: 66
        coding: 68
        instruction: 70
        speed: 50
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 2048
      aliases: []

    # ───────────────────────────────────────────────────────────────────────────
    # ORCA FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/orca-mini:3b
      model: orca-mini:3b
      display_name: Orca Mini 3B
      tier: small
      score:
        overall: 35
        reasoning: 32
        coding: 34
        instruction: 38
        speed: 95
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 2048
      aliases:
        - orca-mini:latest

    - id: ollama/orca-mini:7b
      model: orca-mini:7b
      display_name: Orca Mini 7B
      tier: medium
      score:
        overall: 48
        reasoning: 46
        coding: 48
        instruction: 50
        speed: 85
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 2048
      aliases: []

    - id: ollama/orca-mini:13b
      model: orca-mini:13b
      display_name: Orca Mini 13B
      tier: large
      score:
        overall: 58
        reasoning: 56
        coding: 58
        instruction: 60
        speed: 70
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 2048
      aliases: []

    # ───────────────────────────────────────────────────────────────────────────
    # OPENCHAT FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/openchat:7b
      model: openchat:7b
      display_name: OpenChat 7B
      tier: medium
      score:
        overall: 55
        reasoning: 54
        coding: 55
        instruction: 56
        speed: 85
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases:
        - openchat:latest

    # ───────────────────────────────────────────────────────────────────────────
    # ZEPHYR FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/zephyr:7b
      model: zephyr:7b
      display_name: Zephyr 7B
      tier: medium
      score:
        overall: 54
        reasoning: 52
        coding: 54
        instruction: 56
        speed: 85
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases:
        - zephyr:latest

    # ───────────────────────────────────────────────────────────────────────────
    # DOLPHIN FAMILY
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/dolphin-llama3:8b
      model: dolphin-llama3:8b
      display_name: Dolphin Llama3 8B
      tier: large
      score:
        overall: 56
        reasoning: 54
        coding: 56
        instruction: 58
        speed: 85
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases:
        - dolphin-llama3:latest

    - id: ollama/dolphin-mixtral:8x7b
      model: dolphin-mixtral:8x7b
      display_name: Dolphin Mixtral 8x7B
      tier: large
      score:
        overall: 70
        reasoning: 68
        coding: 70
        instruction: 72
        speed: 55
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 32768
      aliases:
        - dolphin-mixtral:latest

    # ───────────────────────────────────────────────────────────────────────────
    # OTHER MODELS
    # ───────────────────────────────────────────────────────────────────────────
    - id: ollama/tinyllama
      model: tinyllama
      display_name: TinyLlama 1.1B
      tier: small
      score:
        overall: 22
        reasoning: 18
        coding: 20
        instruction: 28
        speed: 99
        confidence: 0.90
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 2048
      aliases:
        - tinyllama:latest

    - id: ollama/dolphin3:8b
      model: dolphin3:8b
      display_name: Dolphin 3 8B
      tier: medium
      score:
        overall: 54
        reasoning: 52
        coding: 52
        instruction: 58
        speed: 85
        confidence: 0.85
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases:
        - dolphin3:latest

    - id: ollama/command-r
      model: command-r
      display_name: Command-R
      tier: large
      score:
        overall: 68
        reasoning: 66
        coding: 65
        instruction: 72
        speed: 60
        confidence: 0.85
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 128000
      aliases:
        - command-r:latest

    - id: ollama/neural-chat:7b
      model: neural-chat:7b
      display_name: Neural Chat 7B
      tier: medium
      score:
        overall: 52
        reasoning: 50
        coding: 50
        instruction: 55
        speed: 88
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases:
        - neural-chat:latest

    - id: ollama/starling-lm:7b
      model: starling-lm:7b
      display_name: Starling LM 7B
      tier: medium
      score:
        overall: 55
        reasoning: 54
        coding: 54
        instruction: 57
        speed: 85
        confidence: 0.95
      capabilities:
        vision: false
        function_calling: false
        json_mode: true
        streaming: true
        system_prompt: true
      context_window: 8192
      aliases:
        - starling-lm:latest
