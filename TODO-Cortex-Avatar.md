---
project: Cortex
component: Unknown
phase: Design
date_created: 2026-02-04T00:00:00
source: ServerProjectsMac
librarian_indexed: 2026-02-06T01:16:29.716289
---

# TODO: Cortex Avatar

## GUI Agent Pattern (from UI-TARS-desktop)
- [ ] **Study UI-TARS vision→action pipeline** — Document how ByteDance handles screen perception to action execution
- [ ] **Prototype VisionCortex component** — Screenshot → Vision Model (LLaVA/Qwen-VL on Ollama) → Action Intent
- [ ] **Design Motor Coordination Layer** — Bridge vision output to Avatar gestures/expressions
- [ ] **Evaluate MLX vs Ollama for vision** — Latency/quality tradeoffs on Pink (RTX 3090)
- [ ] **Avatar "sees and reacts" MVP** — Demo: Avatar responds to on-screen events

## References
- UI-TARS-desktop: https://github.com/bytedance/UI-TARS-desktop
- Evaluation: memory/evaluation-ui-tars-desktop.md
- Model: Vision Lobe → Motor Cortex pipeline

---
*Added: 2026-02-04*
